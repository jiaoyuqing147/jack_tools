import pandas as pd
import os
from sklearn.model_selection import train_test_split
from collections import defaultdict

# ==== é…ç½®å‚æ•° ====
gt_txt_path = r'/home/jiaoyuqing/AlgorithmCodes/datasets/TrainIJCNN2013/gt.txt'
output_dir = './split_lists_7_3'
train_ratio = 0.7
test_ratio = 0.3
random_seed = 42

os.makedirs(output_dir, exist_ok=True)

# ==== è¯»å–gt.txtæ ‡æ³¨ ====
gt_data = pd.read_csv(gt_txt_path, sep=';', header=None, names=['image', 'x1', 'y1', 'x2', 'y2', 'class_id'])

# æ¯å¼ å›¾ç‰‡å…³è”çš„æ‰€æœ‰ç±»åˆ«
image_to_classes = defaultdict(set)
for _, row in gt_data.iterrows():
    img_name = row['image'].replace('.ppm', '')
    image_to_classes[img_name].add(row['class_id'])

image_list = []
class_list = []

for image, classes in image_to_classes.items():
    image_list.append(image)
    class_list.append(sorted(list(classes))[0])  # å–ç¬¬ä¸€ä¸ªç±»åˆ«ç”¨äºåˆ†å±‚ä¾æ®

df = pd.DataFrame({'image': image_list, 'class_id': class_list})

# ==== ç»Ÿè®¡æ¯ä¸ªç±»åˆ«æ•°é‡ ====
class_counts = df['class_id'].value_counts()
single_sample_classes = class_counts[class_counts == 1].index.tolist()

print(f"âš ï¸ ä»…å‡ºç°1æ¬¡çš„ç±»åˆ«æœ‰ï¼š{single_sample_classes}")

# ==== è¿‡æ»¤æ‰ä»…å‡ºç°1æ¬¡çš„ç±»åˆ« ====
df_filtered = df[~df['class_id'].isin(single_sample_classes)].reset_index(drop=True)

print(f"âœ… è¿‡æ»¤åå‰©ä½™æ ·æœ¬æ•°ï¼š{len(df_filtered)}")

# ==== åˆ†å±‚åˆ’åˆ† è®­ç»ƒé›†ä¸æµ‹è¯•é›† ====
train, test = train_test_split(
    df_filtered,
    test_size=test_ratio,
    stratify=df_filtered['class_id'],
    random_state=random_seed
)

# ==== ä¿å­˜åˆ’åˆ†åˆ—è¡¨ ====
def save_list(df_part, filename):
    with open(os.path.join(output_dir, filename), 'w') as f:
        for img in df_part['image']:
            f.write(img + '\n')

save_list(train, 'train.txt')
save_list(test, 'test.txt')

print(f"ğŸ‰ åˆ’åˆ†å®Œæˆï¼šè®­ç»ƒé›† {len(train)} å¼ ï¼Œæµ‹è¯•é›† {len(test)} å¼ ")
print(f"ğŸ“‚ æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{output_dir}")
