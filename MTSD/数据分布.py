import pandas as pd
from sklearn.model_selection import train_test_split
import os

gt_df = pd.read_csv('GT_Detection.txt', delimiter=';', encoding='latin1')
gt_df['File Name'] = gt_df['File Name'].str.strip().str.strip("'").str.lower()

# æ¯å¼ å›¾ç‰‡é‡Œå“ªä¸ªç±»åˆ«æ•°é‡æœ€å¤š
def most_frequent_class(group):
    return group['Class ID'].value_counts().idxmax()

file_classes = gt_df.groupby('File Name').apply(most_frequent_class).reset_index(name='dominant_class')

train_files, val_files = train_test_split(
    file_classes['File Name'],
    test_size=0.3,
    random_state=42,
    stratify=file_classes['dominant_class']
)

os.makedirs('splits', exist_ok=True)
with open('splits/train.txt', 'w') as f:
    f.write('\n'.join(train_files))

with open('splits/val.txt', 'w') as f:
    f.write('\n'.join(val_files))

print(f"è®­ç»ƒé›†ï¼š{len(train_files)} å¼ ")
print(f"éªŒè¯é›†ï¼š{len(val_files)} å¼ ")

# ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡
def count_classes(files):
    subset = gt_df[gt_df['File Name'].isin(files)]
    return subset['Class ID'].value_counts().sort_index()

print("\nğŸ“Š è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒï¼š\n", count_classes(train_files))
print("\nğŸ“Š éªŒè¯é›†ç±»åˆ«åˆ†å¸ƒï¼š\n", count_classes(val_files))
